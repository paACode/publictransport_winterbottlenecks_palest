---
title: "Public Transport Winterbottlenecks"
subtitle: "[Public GitHub Repository](https://github.com/paACode/publictransport_winterbottlenecks_palest)"
author: "Leonard, Stefan, Pascal"
date: "17.05.2025"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
  pdf_document:
    toc: true
    toc_depth: '3'
---


```{r, echo=FALSE , include=FALSE}
## Document related Settings and Libs
require(knitr) 
require(details)    # allows collapsible code blocks
require(gt)         # formats tables nicely

## general language settings
Sys.setenv(LANG = "en")

## Default Settings for R-Chunks
opts_chunk$set(echo = FALSE ,
               include = FALSE,
               comment = NA,
               eval = TRUE,
               message = FALSE,
               warning = FALSE)
```



# Introduction

Zentralbahn, a regional railway company, identified a pressing need to improve the overall performance of its train operations. In response, the company initiated a comprehensive, data-driven investigation aimed at uncovering operational inefficiencies and ensuring long-term service reliability.

As part of this initiative, Zentralbahn engaged an external data science consultant to analyze publicly available OpenTransportData. The consultant’s initial findings revealed a noticeable performance bottleneck in November 2024, likely linked to seasonal, winter-related disruptions.

Although Zentralbahn already had an internal hypothesis regarding the cause, the company is committed to an open, evidence-based approach and is seeking independent confirmation and fresh insights. To broaden the analytical perspective, Zentralbahn partnered with the Hochschule Luzern (HSLU) to carry out a dedicated project using operational data from November 2024.

# Project Goals

<u>**1. Identifying Root Causes of Performance Bottlenecks** </u>

The primary objective is to analyze train operations during **November 2024** to:

- Validate Zentralbahn’s internal assumptions about winter-related disruptions,
- Identify underlying patterns or unexpected factors contributing to performance bottlenecks,
- Provide data-driven recommendations for improving punctuality and operational efficiency on affected lines.

<u>**2. Improving Data Quality Through Predictive Modeling **</u>

A secondary goal is to address known data quality issues in Zentralbahn’s internal datasets. Specifically, several records contain **missing or incorrect train station entries**. HSLU is tasked with:

- Investigating the **November 2024 dataset**, which is considered consistent and reliable,
- Exploring the potential to **predict or classify missing train station values** using available variables such as timestamps, route IDs, or event sequences,
- Developing a methodology that could later be applied to **recover and correct corrupted historical datasets**.


```{r Imports}

library(dplyr)
library(scales)
library(nnet)
library(gamlss.add)
library(dplyr)
library(ggplot2)
library(caret)
theme_set(theme_bw())

```

# A First Look: Predicting Train Cancellations with an Artificial Neural Network

This chapter investigates the predictability of train cancellations without performing prior exploratory data analysis (EDA). It serves as an initial attempt to understand the underlying data. More detailed analyses using simpler and more interpretable models will follow in subsequent chapters.

An artificial neural network (ANN) enables the construction of a predictive model without requiring extensive knowledge of the data structure. It can provide early indications of whether the data contains a meaningful signal.

Therefore, the approach directly attempts to predict whether a train is cancelled, using all available variables, except those that explicitly reveal cancellation status. These are:


- `AN_PROGNOSE` and `AB_PROGNOSE`: Always `NA` when a train is cancelled
- `AN_PROGNOSE_STATUS` and `AB_PROGNOSE_STATUS`: Always `"UNBEKANNT"` when cancelled
- All derived columns such as:
  - `ABFAHRTDELAY_sec`, `ABFAHRTDELAY_min`
  - `ANKUNFTDELAY_sec`, `ANKUNFTDELAY_min`
  - `RUSH_HOUR`, `TAGESZEIT`, `DELAY_CATEGORY`
  - `ZIEL`, `START`
  
These variables are excluded to avoid data leakage.


```{r Read Data}
#### Read in Data ####----------------------------------------------------------
v.to.drop <- c("AN_PROGNOSE", "AN_PROGNOSE_STATUS", "AB_PROGNOSE",
               "AB_PROGNOSE_STATUS",
               "ABFAHRTDELAY_sec", "ABFAHRTDELAY_min",
               "ANKUNFTDELAY_sec", "ANKUNFTDELAY_min", "TAGESZEIT", 
               "RUSH_HOUR", "Delay_Category", "ZIEL", "START", "FAHRT_BEZEICHNER"
)

d.ann<- read.csv("zentrahlbahn_final.csv") %>% 
  select(-all_of(v.to.drop), -starts_with("w_")) # Also drop all weather data


```

```{r Ratio Cancelled}
d.ann.cancelled <- d.ann %>% 
  filter(FAELLT_AUS_TF == TRUE)
cancelled <- nrow(d.ann.cancelled)
tot <- nrow(d.ann)
r.cancelled <- cancelled/tot
rm(d.ann.cancelled)
```


## Data Preparation

As a first step, the distribution of the response variable is examined. An initial analysis indicates that `r percent(r.cancelled)` of the trains in the dataset are cancelled. This was taken into account during data preparation. For the ANN to work, the following steps were performed:

1. Convert character and logical variables to factors  
2. Remove factors with fewer than two levels (contain no information)  
3. Use only factor variables to keep the ANN simple  
4. Drop time columns because they include a large number of levels  
5. Perform one-hot encoding  
6. Stratify train and test data  
7. Downsample train data to ensure an equal number of cancelled and uncancelled trains  



```{r Perpare Data}
convert_all_possible_to_factor <- function(df) {
  df[] <- lapply(df, function(col) {
    if (is.character(col) || is.logical(col)) {
      as.factor(col)
    } else {
      col
    }
  })
  return(df)
}
drop_factors_with_less_than_two_levels <- function(df) {
  # Identify factors with fewer than two levels (0 or 1)
  small_level <- sapply(df, function(x) is.factor(x) && length(levels(x)) < 2)
  
  # Remove those columns
  df_clean <- df[, !small_level, drop = FALSE]
  
  return(df_clean)
}
drop_non_factors <- function(df) {
  df[, sapply(df, is.factor), drop = FALSE]
}

d.ann <- convert_all_possible_to_factor(d.ann)
d.ann <- drop_factors_with_less_than_two_levels(d.ann)
d.ann <- drop_non_factors(d.ann) 
d.ann <- d.ann %>% select(!ANKUNFTSZEIT) #Remove Time 
d.ann <- d.ann %>% select(!ABFAHRTSZEIT) #Remove Time 

d.ann.rv <-  d.ann %>% select(FAELLT_AUS_TF) # Response Variable
d.ann.pred <-  d.ann %>% select(BETRIEBSTAG, LINIEN_TEXT,HALTESTELLEN_NAME) 
# BEtriebstag, LinienText and Haltestellenname are the predictors for the model


#Create Dummy Variables 
dummies <- dummyVars(~ ., data = d.ann.pred)
data_dummies <- predict(dummies, newdata = d.ann.pred)

# Add one hot encoded predictors to RV
d.ann.rdy <- bind_cols(d.ann.rv, data_dummies)

```


```{r Test and Train Data, echo =TRUE, cached=TRUE}
set.seed(123)
train_index <- createDataPartition(d.ann.rdy$FAELLT_AUS_TF, p = 0.8, list = FALSE)

train <- d.ann.rdy[train_index, ]
test <- d.ann.rdy[-train_index, ]

# Make sure there are as much Cancelled as Non Cancelled observations in Train Data
majority_class <- train[train$FAELLT_AUS_TF == FALSE, ]
minority_class <- train[train$FAELLT_AUS_TF == TRUE, ]

# Sample from majority class to match minority class size
set.seed(123)
majority_downsampled <- majority_class[sample(nrow(majority_class), nrow(minority_class)), ]

# Combine minority class with downsampled majority class
train_downsampled <- rbind(minority_class, majority_downsampled)

# Shuffle rows 
train_downsampled <- train_downsampled[sample(nrow(train_downsampled)), ]



```

## Building the Network

Building the Network included a lot of trial and error. Because for many configurations the model did not converge. In the end 3 predictors could be found which lead to quite good prediction:

- BETRIEBSTAG
- LINIEN_TEXT
- HALTESTELLEN_NAME



```{r Build the network, echo=TRUE, cache =TRUE, eval=TRUE}


set.seed(412)
fealltaus_net <- nnet(FAELLT_AUS_TF ~  ., data = train_downsampled, size=15, maxit=500, range=0.1, decay=1e-4, MaxNWts = 10000)
```

```{r Plot NET, include =TRUE}
plot(fealltaus_net)
```

## Results

The model successfully predicts train cancellations using only three categorical predictors: **BETRIEBSTAG**, **LINIEN_TEXT**, and **HALTESTELLEN_NAME**. Despite the test data containing 80% uncancelled and 20% cancelled trains, the model performs well thanks to stratification and downsampling during training. These results suggest that these predictors are promising candidates for more detailed modeling and analysis.


```{r Test the Network, include=TRUE}
test.n.result <- test %>% select(-FAELLT_AUS_TF)
pred <- predict(fealltaus_net, test.n.result, type="class")
cm_nn <- table(pred=pred, true=test$FAELLT_AUS_TF)
cm_nn

confusionMatrix(as.factor(pred), as.factor(test$FAELLT_AUS_TF))

```


# Generalised Additive Models GAM

In this project, we apply Generalized Additive Models (GAMs) to analyze the effects of various predictors on train delays, specifically focusing on the response variables ANKUNFTDELAY_min (arrival delay in minutes) and ABFAHRTDELAY_min (departure delay in minutes). 
Due to the limited availability of continuous variables in our dataset these two delay metrics will be the response variables we will focus on.
A key subset of our predictors is related to weather conditions. However, because the ZB Bahn railway line spans multiple climatic regions, 
comparing weather-related predictors across all stations introduces variability that may obscure meaningful patterns. To address this, we restrict our analysis to a subset of stations located within the Lucerne region, where the climate is more uniform. 
This allows for a more reliable interpretation of the relationship between weather conditions and train delays.

```{r gam-general-codes-subset, include=TRUE, echo=TRUE}
# General codes
library(dplyr)
library(ggplot2)
library(mgcv)
library(tidyr)
library(caret)


#Creating subset

zb_final <- read.csv("zentrahlbahn_final.csv", header = TRUE, stringsAsFactors = TRUE)

# Define the specific Haltestellen in the region of Lucerne
haltestellen_to_keep <- c("Luzern", "Luzern Allmend/Messe", "Kriens Mattenhof", "Horw", 
                          "Hergiswil Matt", "Hergiswil NW", "Stansstad", "Stans")

zb_final_subset <- zb_final %>%
  filter(HALTESTELLEN_NAME %in% haltestellen_to_keep)

# Create new columns with delay in minutes
zb_final_subset <- zb_final_subset %>%
  mutate(
    ABFAHRTDELAY_min = ABFAHRTDELAY_sec / 60,
    ANKUNFTDELAY_min = ANKUNFTDELAY_sec / 60
  )


#Removing rows NA in ANKUNFTDELAY_min and ABFAHRTDELAY_min

zb_final_subset <- zb_final_subset %>%
  filter(!is.na(ANKUNFTDELAY_min))

sum(is.na(zb_final_subset$ANKUNFTDELAY_min)) #Checking if ANKUNFTDELAY_min NA is 0

zb_final_subset <- zb_final_subset %>%
  filter(!is.na(ABFAHRTDELAY_min))

sum(is.na(zb_final_subset$ABFAHRTDELAY_min)) #Checking if ABFAHRTDELAY_min NA is 0

#Reducing the subbset just with the relevant columns

zb_final_subset <- zb_final_subset %>% select(BETRIEBSTAG, LINIEN_TEXT, HALTESTELLEN_NAME, ANKUNFTSZEIT, AN_PROGNOSE, ABFAHRTSZEIT, AB_PROGNOSE, ABFAHRTDELAY_min, ANKUNFTDELAY_min, Delay_Category, TAGESZEIT, RUSH_HOUR, w_precip_mm_Luzern, w_temp_avg_c_Luzern)

```

R assumes for GAM models usually the gaussian family for the response variables. Therefore, let's have a look if the response variables ANKUNFTDELAY_min and ABFAHRTDELAY_min are gaussian distributed. 

```{r first-histogram, include=TRUE, echo=TRUE}

par(mfrow = c(1, 2))


hist(zb_final_subset$ANKUNFTDELAY_min, main = "Histogram of ANKUNFTDELAY_min", xlab = "ANKUNFTDELAY_min", col = "lightblue", breaks = 100, xlim = c(-2,8))


hist(zb_final_subset$ABFAHRTDELAY_min, main = "Histogram of ABFAHRTDELAY_min", xlab = "ABFAHRTDELAY_min", col = "lightblue", breaks = 100, xlim = c(-2,8))


```

We see that both response variables are not normally distributed They seem to be right skewed. Lets check with the QQ plots. 

```{r first-qqplot, include=TRUE, echo=TRUE}

par(mfrow = c(1, 2))

qqnorm(zb_final$ANKUNFTDELAY_min, main = "QQ Plot of ANKUNFTDELAY_min")
qqline(zb_final$ANKUNFTDELAY_min, col = "lightblue")

qqnorm(zb_final_subset$ABFAHRTDELAY_min, main = "QQ Plot of ABFAHRTDELAY_min")
qqline(zb_final_subset$ABFAHRTDELAY_min, col = "lightblue")

```

The QQ plots reveal that the response variables are right-skewed, which aligns with expectations. In real-world train operations, early arrivals or departures are relatively uncommon compared to delays. Moreover, the distribution indicates that longer delays occur less frequently than shorter ones, reflecting 
typical delay patterns observed in Swiss public transportation.For this reason, we restrict our dataset for the 
GAM analysis to observations with delays between -2 and +4 minutes, aiming to ensure a distribution that more closely 
approximates the Gaussian assumption required by the model.

```{r second-histogram, include=TRUE, echo=TRUE}

par(mfrow = c(1, 2))

zb_final_subset <- zb_final_subset %>%
  filter(ABFAHRTDELAY_min >= -2 & ABFAHRTDELAY_min <= 4,
         ANKUNFTDELAY_min >= -2 & ANKUNFTDELAY_min <= 4)


hist(zb_final_subset$ANKUNFTDELAY_min, main = "Histogram of ANKUNFTDELAY_min", xlab = "ANKUNFTDELAY_min", col = "lightgreen", breaks = 50, xlim = c(-2,4))


hist(zb_final_subset$ABFAHRTDELAY_min, main = "Histogram of ABFAHRTDELAY_min", xlab = "ABFAHRTDELAY_min", col = "lightgreen", breaks = 50, xlim = c(-2,4))


```

The histogram indicates an approximately normal distribution. Therefore, the dataset is now suitable for fitting with Generalized Additive Models (GAMs).

```{r gam-Ankunft-temp, include=TRUE, echo=TRUE}

gam_Ankunft_temp <- gam(ANKUNFTDELAY_min ~ s(w_temp_avg_c_Luzern), data = zb_final_subset) 

summary (gam_Ankunft_temp)

```

The p-value associated with the smooth term is close to zero, providing strong evidence that the average temperature in Lucerne has a statistically significant effect on arrival delays. The estimated effective degrees of freedom (edf ≈ 9) suggest a moderately complex, non-linear relationship. However, the adjusted R-squared value of 0.036 and the explained deviance of only 3.67% indicate that the model captures only a small portion of the variation in arrival delays. Thus, while the effect is significant, temperature alone does not explain much of the delay variability.

```{r gam-temp-precip-tageszeit-linien_text, include=TRUE, echo=TRUE}

gam_temp_precip_tageszeit_linien_text <- gam(ABFAHRTDELAY_min ~ TAGESZEIT + LINIEN_TEXT + s(w_temp_avg_c_Luzern) + s(w_precip_mm_Luzern), data = zb_final_subset) 

summary(gam_temp_precip_tageszeit_linien_text)

plot(gam_temp_precip_tageszeit_linien_text, residuals = TRUE, select = 1,main = "Effect of Temperature on Departure Delay")
plot(gam_temp_precip_tageszeit_linien_text, residuals = TRUE, select = 2, main = "Effect of Precipitation on Departure Delay")
```

Interpretation of Parametric Coefficients:
The reference levels for the categorical predictors are evening for TAGESZEIT and EXT for LINIEN_TEXT. Under these baseline conditions (evening, 0°C, and 0 mm precipitation), the EXT line of Zentralbahn (ZB) in the Lucerne region has an average departure delay of approximately 1.25 minutes. 

The effect of time of day is substantial; compared to the evening, trains during luncht time experience on average 0.30 minutes less delay, those in the afternoon 0.16 minutes less, during night operations 0.30 minutes less and in the morning 0.12 minutes less delay. 

Regarding train lines, the IR line shows a reduction of 0.22 minutes compared to EXT, although this difference is not statistically significant (p = 0.5). In contrast, the PE line exhibits the largest reduction, with trains experiencing on average 2.32 minutes less delay than EXT, a difference that is statistically significant. Likewise, the S4, S41, S44, and S55 lines show significantly reduced delays compared to EXT, with reductions of 0.84, 1.35, 1.04, and 1.96 minutes, respectively, while the S5 line’s difference (0.51 minutes less) is not statistically significant.

Interpretation of the Smooth Terms:
The smooth term for average temperature has an estimated effective degrees of freedom (edf) of approximately 9, indicating a moderately complex non-linear relationship with departure delay. We have strong evidence that it is not 0 with a p-value < 0.05. The corresponding plot reveals that temperatures between 0 and 6°C have a stronger effect on departure delay, whereas between roughly 6–7°C and 8–10°C the effect is minimal. 

Similarly, the smooth term for average precipitation (w_precip_mm_Luzern) has an edf of about 8.32, suggesting a moderately complex non-linear relationship. We have strong evidence that it is not 0 with a p-value < 0.05. 

The precipitation plot shows a clear non-linear relationship between precipitation and departure delays. There is a strong effect at lower precipitation levels (up to approximately 20 mm), after which the curve flattens between around 22 mm and 50 mm, indicating a reduced impact on delays. One possible explanation for this flattening is that higher precipitation levels may coincide with times of reduced train activity—such as during the night—when fewer departures occur, thereby minimizing the observed effect on overall delays. Additionally, since the dataset only covers November 2024, it is possible that there were relatively few instances of heavy precipitation during this period in the Lucerne region, which may limit the model's ability to capture stronger effects at higher precipitation levels.

Overall Model Performance:
The adjusted R² value of 0.119 means that the model explains around 11.9% of the variation in departure delays. This suggests that the predictors included in the model have a measurable effect on delays, but a large part of the variation (around 88%) is still not accounted for. This can be considered as not unusual in real-world transportation data, where many factors that influence delays—such as technical problems, temporary disruptions, staffing issues or operational decisions—are not included in the dataset. While the model successfully identifies several statistically significant predictors, it also shows that more variables or more complex modeling approaches might be needed to better capture all the factors that contribute to departure delays.

# Generalised Linear Model with family set to Binomial

```{r binary-codes-subset, include=TRUE, echo=TRUE}

zb_final <- read.csv("zentrahlbahn_final.csv", header = TRUE, stringsAsFactors = TRUE)

#Subset
zb_final_binominal <- zb_final %>%
  mutate(
    Train_Delayed = case_when(
      Delay_Category == "On Time" ~ FALSE,    
      Delay_Category == "Unknown" ~ NA,
      Delay_Category %in% c("Minor Delay", "Moderate Delay", "Significant Delay") ~ TRUE,  
      TRUE ~ NA  # Handle any other unrecognized categories as NA
    ),
    
   
    Train_RUSH_HOUR = case_when(
      RUSH_HOUR == "rush_hour_none" ~ FALSE,
      RUSH_HOUR %in% c("rush_hour_vormittag", "rush_hour_abend") ~ TRUE,
      is.na(RUSH_HOUR) ~ NA,  # Handle NA values properly
      TRUE ~ NA  # Any other unrecognized or unexpected RUSH_HOUR values are NA
    )
  ) %>%
  select(
    1:(match("Delay_Category", names(.))),  # Columns up to Delay_Category
    Train_Delayed,  # Add Train_Delayed after Delay_Category
    (match("Delay_Category", names(.)) + 1):(match("RUSH_HOUR", names(.))),  # Columns between Delay_Category and RUSH_HOUR
    Train_RUSH_HOUR,  # Add Train_RUSH_HOUR after RUSH_HOUR
    (match("RUSH_HOUR", names(.)) + 1):ncol(.)  # Columns after RUSH_HOUR
  )

# Create new columns with delay in minutes
zb_final_binominal <- zb_final_binominal %>%
  mutate(
    ABFAHRTDELAY_min = ABFAHRTDELAY_sec / 60,
    ANKUNFTDELAY_min = ANKUNFTDELAY_sec / 60
  )

#Reducing the subset with only relevant columns
zb_final_binominal <- zb_final_binominal %>% select(BETRIEBSTAG, LINIEN_TEXT, FAELLT_AUS_TF, HALTESTELLEN_NAME, ANKUNFTSZEIT, AN_PROGNOSE, AN_PROGNOSE_STATUS, ABFAHRTSZEIT, AB_PROGNOSE, AB_PROGNOSE_STATUS, ABFAHRTDELAY_min, ANKUNFTDELAY_min, Delay_Category, Train_Delayed, TAGESZEIT, RUSH_HOUR, Train_RUSH_HOUR)


#Removing rows NA in ANKUNFTDELAY_min

zb_final_binominal <- zb_final_binominal %>%
  filter(!is.na(ANKUNFTDELAY_min))

sum(is.na(zb_final_binominal$ANKUNFTDELAY_min)) #Checking if ANKUNFTDELAY_min NA is 0

zb_final_binominal <- zb_final_binominal %>%
  filter(!is.na(ABFAHRTDELAY_min))

sum(is.na(zb_final_binominal$ABFAHRTDELAY_min)) #Checking if ABFAHRTDELAY_min NA is 0

# Convert the Train_Delayed to numeric (0 = FALSE, 1 = TRUE) otherwise we can not use it with a logistic regression model
zb_final_binominal$Train_Delayed <- as.numeric(zb_final_binominal$Train_Delayed)

```

```{r first-plotting, include=TRUE, echo=TRUE}
#Plotting the data

zb_final_binominal %>%
  group_by(LINIEN_TEXT) %>%
  summarise(ProportionDelayed = mean(Train_Delayed, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(LINIEN_TEXT, ProportionDelayed), y = ProportionDelayed)) +
  geom_point(size = 3, color = "steelblue") +
  labs(x = "Train Line", y = "Proportion Delayed") +
  theme_minimal()

```

In this plot, we can see that the EXT line has the highest proportion of delayed trains, with approximately 40% of its services experiencing delays. The line with the second highest delay rate is the R71, where around 24% of trains are delayed. 
On the other end of the spectrum, the S41 line shows the lowest delay rate, with only about 10% of its trains being delayed.


To predict whether a train is delayed, we use a binomial logistic regression with Train_Delayed as the binary response variable and LINIEN_TEXT (train line) as the predictor. This model estimates how the probability of delay varies across different train lines.

```{r glm-delay, include=TRUE, echo=TRUE}

glm_delay <- glm(Train_Delayed ~ LINIEN_TEXT, family = "binomial", data = zb_final_binominal)

summary(glm_delay)

```

The number of Fisher Scoring iterations is 7, which is an acceptable value.
The dispersion parameter in the model was calculated by dividing the residual deviance (21375) by the residual degrees of freedom (57209), yielding a value of 0.374. This value, being less than 1, indicates that there is no overdispersion in the data. Therefore, the binomial model is an appropriate fit for the dataset, and no adjustments for overdispersion are necessary.

On one hand, the p-values for almost all the train lines are very small, indicating that the train lines have a statistically significant effect on whether a train is delayed or not. Since the coefficients for the train lines are negative, it suggests that the different train lines have a lower likeliness of being delayed compared to the baseline train line.

On the other hand, the train line R71, which operates between Meiringen and Innertkirchen, has a p-value above 0.05. This suggests that R71 does not have 
a statistically significant impact on whether a train is delayed or not. This is interesting because, when the predictors were plotted, R71 was the line with 
the second-highest probability of delay, with an average delay of around 24%.
The reason for this contradiction could be that while the R71 line might often experience delays, the variance of the delays might be quite narrow. To explore this, let's take a look at the boxplot of the train delays by line.

```{r boxplot-ANKUNFTDELAY_min-LINIEN_TEXT, include=TRUE, echo=TRUE}

boxplot(ANKUNFTDELAY_min ~ LINIEN_TEXT , data = zb_final_binominal)

```

In the boxplot, we can see that the R71 has a relatively large variance between the 25th and 75th percentiles of the data. 
Nevertheless, R71 has fewer outliers compared to the other lines. The delays on R71 might be consistent, but not extreme enough to be detected as a significant predictor in the logistic regression model.

Just because R71 has a relatively high average of being delay doesn't necessarily mean that the line itself significantly affects the likelihood of delay when considering all other factors. The logistic regression model is trying to predict the probability of a delay (yes/no) based on various predictors. Other variables—such as weather, time of day, or operational factors—might influence whether a delay occurs for R71 trains.

Lets have now a look at the coefficients of glm_delay

```{r exp-coef-glm-delay, include=TRUE, echo=TRUE}

exp(coef(glm_delay)) %>% round(digits=2)

```

To interpret the effect of different train lines on the likelihood of delays, the logistic regression coefficients were exponentiated to obtain odds ratios. These odds ratios provide a clearer understanding of how the odds of a delay on each line compare to the baseline category, which in this model is the train line EXT. All other train lines show odds ratios significantly below 1, indicating a lower likelihood of delay relative to EXT. For instance, trains on line IR have odds of being delayed that are only 9% of those on line EXT, while line S41 shows an even stronger reduction, with odds at just 1%. Other notable examples include lines PE and R70, each with odds around 7–9% of the baseline, and line S5, with only 5% of the odds of a delay compared to EXT. These findings suggest, as already seen in the previous plots, that line EXT has a particularly high likelihood of delays, while other lines operate with considerably greater punctuality.

The next step in our analysis involves simulating predictions based on the logistic regression model to better understand the likelihood of train delays. 
This will help us evaluate the model's performance and gain insights into the probability of delays across different train lines.

```{r simulation-glm-delay, include=TRUE, echo=TRUE}

# Set seed for reproducibility
set.seed(123)

# Simulate new data based on existing data's structure (e.g., random values for LINIEN_TEXT)
simulated_data <- data.frame(
  LINIEN_TEXT = sample(levels(zb_final_binominal$LINIEN_TEXT), 10000, replace = TRUE) #increased the n of trials in order to have higher sampling and higher probability range
)

# Predict the probability of delay for these simulated data points
simulated_data$predicted_prob <- predict(glm_delay, newdata = simulated_data, type = "response")

# Show the first few rows of the simulated data
head(simulated_data)

# Plotting the simulated probabilities of train delays by train line

ggplot(simulated_data, aes(x = reorder(LINIEN_TEXT, predicted_prob), y = predicted_prob, color = LINIEN_TEXT)) +
  geom_jitter(alpha = 0.5, width = 0.2, height = 0) +
  labs(x = "Train Line", y = "Simulated Probability of Delay") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels
    panel.border = element_blank(), # Remove the box around the plot
    legend.position = "none" # Remove the legend
  )
```

In this plot, we can see that the simulated data is similar to the original data. The EXT line shows a simulated probability of delay of approximately 40%, while the R71 line has a simulated probability delay of around 24%. 
On the other end, the S41 line exhibits the lowest simulated probability of delay, with only about 1% of its services experiencing delays.

Lets now compare our simulated data with our real dataset.

```{r summary-simulated-data, include=TRUE, echo=TRUE}

summary(simulated_data)

```

The mean of the simulated data is 0.105. This is the reason why we cannot take a threshold of 0.5. This would result in nearly all cases being classified as non-delayed, since very few predicted probabilities exceed 0.5—ultimately leading to extremely poor sensitivity and almost no true positives.
Several thresholds were tested to determine the optimal cut-off point for classifying delays based on the predicted probabilities. Thresholds such as 0.03, 0.08, and 0.1 were evaluated, but they either led to a very low specificity or poor sensitivity. A threshold of 0.2 appeared to offer the most reasonable trade-off between correctly identifying delayed trains (sensitivity) and avoiding false delay predictions (specificity), making it the most balanced choice for this model.

```{r confusion-matrix-simulated-data, include=TRUE, echo=TRUE}
# Discretize the simulated data
simulated_data$simulated_delay <- ifelse(simulated_data$predicted_prob > 0.2, 1, 0)

# Sample from the simulated data with replacement to match the number of rows in the real dataset
set.seed(123)
simulated_sample <- simulated_data[sample(1:nrow(simulated_data), nrow(zb_final_binominal), replace = TRUE), ]

# Create the confusion matrix
# Making sure the factor levels are the same for both the simulated data and the real data
simulated_sample$simulated_delay <- factor(simulated_sample$simulated_delay, levels = c(0, 1))
zb_final_binominal$Train_Delayed <- factor(zb_final_binominal$Train_Delayed, levels = c(0, 1))


# Comparing the real data delays with the simulated delays
conf_matrix <- confusionMatrix(as.factor(simulated_sample$simulated_delay), as.factor(zb_final_binominal$Train_Delayed))

# Printing the confusion matrix
print(conf_matrix)
```

The model's accuracy is 76.96%, which at first glance suggests decent performance, but this metric is heavily influenced by the significant imbalance between delayed and non-delayed trains in the dataset. Due to the high punctuality of Swiss trains, the vast majority of observations are non-delays, making accuracy a somewhat misleading indicator of model effectiveness. 

Sensitivity, which captures how well the model identifies actual delays, is fairly high at 79.8%, indicating that the model detects most delay cases. However, specificity is low at 20.0%, meaning it struggles to correctly identify non-delayed trains, frequently labeling them as delayed. The model's precision is high at 95.2%, so when it predicts a delay, it is usually right. 

On the other hand, the negative predictive value is low at 4.7%, reflecting poor performance in correctly predicting trains that are on time.

Balanced accuracy, which considers both sensitivity and specificity, is 49.9% suggesting the model performs no better than random guessing when it comes to balancing delay and non-delay predictions.

Despite strong precision for delays, the inability to reliably detect non-delays remains a key weakness. Several threshold values were tested to improve this balance but none led to a meaningful improvement in the confusion matrix. A threshold of 0.2 offered the best compromise between sensitivity and specificity among the tested options. 

For future work, further adjustments addressing the class imbalance and a more refined threshold selection process may be necessary to enhance model reliability across both outcome classes.

# Use of Generative AI

ChatGPT can be a valuable tool for various aspects of programming, particularly for detecting syntax errors and generating initial plots quickly. It provides immediate feedback, making it easier for users to identify issues and visually present their data. This speed and convenience can help jump-start the coding process, especially for beginners or when exploring new concepts.

However, there are limitations to relying solely on ChatGPT for more complex tasks. While it can help create basic plots, developing more specific or tailored visualizations often leads users down a “rabbit hole,” where time is spent refining the plot rather than focusing on the underlying analysis. Additionally, implementing modularity in code is challenging when using ChatGPT. It requires a deeper understanding of programming concepts to ensure code is reusable, maintainable, and efficient, which cannot always be achieved through AI-generated solutions alone.

Another significant concern is that the code generated by ChatGPT is often done quickly, but it may lack proper documentation and clarity. Without adequate comments and explanations, the code can be difficult to read and understand, posing challenges for collaboration or future revisions. Furthermore, ChatGPT sometimes generates overly complex solutions when a simpler, more efficient approach could be used, which could be easily implemented with just a few lines of code if the programmer has a solid grasp of the task at hand.

As data scientists, it is essential not only to understand the technical aspects of coding but also to gain a deep understanding of the data itself. Data analysis is a creative process that involves continuous iteration, exploration, and insight. To arrive at meaningful conclusions, data scientists must engage with domain experts and other stakeholders throughout the analysis process. This collaboration helps ensure that the results are accurate, relevant, and actionable, ultimately leading to well-informed decisions.

In conclusion, while ChatGPT offers valuable assistance in coding, especially for quick debugging and basic tasks, it is important for users to ensure they understand their code thoroughly and the data they are working with. Achieving effective modularity, clarity, and efficiency requires a combination of technical expertise and creativity, with ongoing collaboration, to ensure the success of data analysis projects


# Conclusion

The analysis confirmed what Zentralbahn had likely anticipated: a **severe thunderstorm** caused substantial disruption to train operations, as documented in the official report on the reopening of the **Meiringen–Interlaken Ost** route on **November 25, 2024**([source](https://www.zentralbahn.ch/de/kennenlernen/die-zentralbahn/einblicke/wiedereroeffnung-der-strecke-meiringen-interlaken-ost-am-25-november-2024)).

In addition to this expected finding, several other valuable insights were uncovered through the application of various statistical models. Importantly, **the models developed can be used to predict delays under different operational conditions**, providing a foundation for proactive planning and decision-making.



<u>**1. High Delay Probability for "EXT" Trains**</u>  

Extra trains ("EXT") were found to have the highest probability of delay. A likely reason is the use of older trainsets, which may be less reliable or slower to adapt to schedule changes.  
The model allows for **predicting the likelihood of delay** for individual train entries based on their train type and other features, enabling early intervention or scheduling adjustments.

<u>**2. Limited Influence of Weather**</u>

Weather conditions showed only a **limited direct effect** on train delays. This is likely due to **low temporal resolution** in the available weather data.  
Still, the model can be used to **quantify expected delay contributions from weather** where data is available, and it is ready to be improved once finer-grained weather data is incorporated.

<u>**3. Operational Patterns and Delay Clusters**</u>  

The model identified three distinct operational time categories, with **rush hours** exhibiting the most frequent delays. While traffic volume is a plausible factor, this recurring pattern hints at **systemic scheduling or resource constraints**.  
With this model, it is possible to **predict the expected number of delays per hour** based on operational time and other variables, supporting staffing and dispatch decisions.

Defined operational periods:

- **Low Operation:** 00:00 – 06:00  
- **Rush Hour:** 06:00 – 09:00, 11:00 – 14:00, and 16:00 – 20:00  
- **Normal Operation:** All other times

<u>**4. Noteworthy Dates and Events**</u>

The following dates and events stood out in the analysis and can inform the refinement of future models:

- **Extreme Delay Days:** November 22 and 23, 2024 – identified as outlier days with unusually high delays  
- **Route Reopening:** From **November 25, 2024**, the Meiringen–Interlaken Ost line resumed normal service ([details](https://www.zentralbahn.ch/de/kennenlernen/die-zentralbahn/einblicke/wiedereroeffnung-der-strecke-meiringen-interlaken-ost-am-25-november-2024))  
- **Return to Normal Operation:** Delay patterns normalized after the disruption, serving as a **benchmark period for predictive model calibration**
